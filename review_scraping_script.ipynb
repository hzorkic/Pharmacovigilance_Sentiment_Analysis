{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c86f5fe",
   "metadata": {},
   "source": [
    "# Scrape Drug Reviews from Drugs.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce0fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285c9397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "for i in range(1999, 2022):\n",
    "    print(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d143ad",
   "metadata": {},
   "source": [
    "## Scrape drug reviews from Drugs.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe11b53",
   "metadata": {},
   "source": [
    "We create a dataframe with the following format:\n",
    "\n",
    "#### | drug name | review | rating |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00122ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    polarity                                             review\n",
      "0        1.0  I am desperate to get this implant out.\\nIt ha...\n",
      "1        1.0  The first time I got the Nexplanon implant I h...\n",
      "2        1.0  I definitely agree with everyone here saying t...\n",
      "3        1.0  I had Nexplanon for for 6 months because a fri...\n",
      "4        1.0  I got nexplannon in 2020 at some point. I have...\n",
      "..       ...                                                ...\n",
      "808      0.0  This is my third year on Junel Fe. It is the b...\n",
      "809        0  p>\\t\\tâ€œI know a lot of people come here to lea...\n",
      "811      1.0  Awful!! Terrible!! I used NuvaRing for an IVF ...\n",
      "812      1.0  I was on the Nuvaring for years. It was the on...\n",
      "813      0.0  I avoided this for too long due to reviews her...\n",
      "\n",
      "[754 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_webpage(link):\n",
    "    '''Get the contents of a webpage.\n",
    "    Input: \n",
    "        link = Link to the desired webpage\n",
    "    Output: Beautiufl Soup Object containing the HTML data\n",
    "    '''\n",
    "    # load the webpage content \n",
    "    r = requests.get(link)\n",
    "    # convert to a beautiful soup object \n",
    "    webpage = bs(r.content)\n",
    "    return r, webpage\n",
    "\n",
    "\n",
    "def get_reviews(url_, drug_name, drug_reviews, date_cutoff=False):\n",
    "    '''Get all of the reviews of a specific drug\n",
    "    Input: \n",
    "        drug_name = name of the drug\n",
    "        drug_reviews = number of reviews\n",
    "        date_cutoff = Do you want to limit the date of reviews collected?\n",
    "    Output: A list containing a list for each review: [str('Review goes here'), int(rating)]\n",
    "    '''\n",
    "    #------------------------#\n",
    "    # 1. initalize variables #\n",
    "    #------------------------#\n",
    "    reviews, isHaveNextPage, page = [], True, 0\n",
    "    date_cutoff = tuple([str(i) for i in range(1999, int(date_cutoff)+1)])\n",
    "    \n",
    "    #---------------------------------------------------------#\n",
    "    # 2. \"clicking\" the \"#### Reviews\" hyperlink in the table #\n",
    "    #---------------------------------------------------------#\n",
    "    review_page_url = url_\n",
    "    \n",
    "    #---------------------------------------#\n",
    "    # 3. cycle through each page of reviews #\n",
    "    #---------------------------------------#\n",
    "    while isHaveNextPage: \n",
    "        \n",
    "        # access the page and sort the reviews by most recent reviews\n",
    "        r_, review_page_content = get_webpage(review_page_url + f\"?sort_reviews=most_recent&page={page}\")\n",
    "        \n",
    "        # TO-DO: There is an issue here with grabbing reviews after page 5\n",
    "        list_of_review_boxes = review_page_content.find_all(\"div\", {\"class\":\"ddc-comment ddc-box ddc-mgb-2\"})\n",
    "        \n",
    "        # grab the date, review paragraph, and rating\n",
    "        for review in list_of_review_boxes:\n",
    "            # 1. find the date, if it is at the cutoff year, ignore\n",
    "            head = review.find(\"div\", {\"class\":\"ddc-comment-header\"})\n",
    "            date = head.find(\"span\", string=re.compile(\", \")).string\n",
    "            if date.endswith(date_cutoff):\n",
    "                return reviews\n",
    "            \n",
    "            # 3. get the review paragraph\n",
    "            if review.p.b:\n",
    "                review_paragraph = str(review.p.b.next_sibling).strip()[1:-1]\n",
    "            else:\n",
    "                review_paragraph = str(review.p).strip()[1:-1]\n",
    "            \n",
    "            # 2. find the review rating, if it exists, if not, ignore\n",
    "            sentiment = None\n",
    "            if review.find(\"div\", {\"class\":\"ddc-rating-summary\"}):\n",
    "                rating = int(review.find(\"div\", {\"class\":\"ddc-rating-summary\"}).span.b.string)\n",
    "                if rating < 5:\n",
    "                    sentiment = int(1)\n",
    "                else:\n",
    "                    sentiment = int(0)\n",
    "    \n",
    "            reviews.append(list([sentiment, review_paragraph]))\n",
    "            \n",
    "        # go to next page if not on the last page\n",
    "        if review_page_content.find_all(\"li\",class_='ddc-paging-item-next') is None:\n",
    "            isHaveNextPage=False\n",
    "        page += 1\n",
    "    print(review)\n",
    "    return reviews\n",
    "    \n",
    "\n",
    "    \n",
    "#---------------#\n",
    "# Main Function #\n",
    "#---------------#\n",
    "\n",
    "def main():\n",
    "    data = pd.DataFrame(columns=['polarity', 'review'])\n",
    "\n",
    "    # 1. Get data from the \"contraceptives\" page on drugs.com\n",
    "    url = \"https://www.drugs.com/drug-class/contraceptives.html\"\n",
    "    r, webpage = get_webpage(url)\n",
    "\n",
    "    # 2. Get table with drug names, reviews, etc.\n",
    "    table_body = webpage.find(\"table\", {\"class\":\"ddc-table-sortable\"})\n",
    "    # create an empty dataframe\n",
    "    drug_data = pd.DataFrame(columns=['date', 'sentiment', 'review'])\n",
    "\n",
    "    # loop through the table with drug names\n",
    "    for row in table_body.find_all(\"tr\")[1:-1]:\n",
    "        # get the drug name\n",
    "        drug_name = row.td.a.b.string\n",
    "\n",
    "        # get the number of reviews\n",
    "        if row.find(\"a\", {\"class\":\"ddc-text-nowrap\"}):\n",
    "            # grab the number and convert the string into an integer\n",
    "            drug_reviews = row.find(\"a\", {\"class\":\"ddc-text-nowrap\"}).string.split(' ')[0]\n",
    "            drug_reviews = int(drug_reviews.replace(',', ''))\n",
    "\n",
    "            url_ = \"https://www.drugs.com\" + str(row.find(\"a\", {\"class\":\"ddc-text-nowrap\"}, href=True)['href'])\n",
    "            # if there are more than 100 reviews, we add it to the dataframe\n",
    "            if drug_reviews >= 100:\n",
    "                # get the reviews, dates, and sentiments of all drug reviews posted after 2021\n",
    "                reviews = get_reviews(url_, drug_name, drug_reviews, '2021')\n",
    "                #print(\"Done with, \", drug_name, \"reviews\")\n",
    "                reviews = pd.DataFrame(reviews, columns=['polarity', 'review'])\n",
    "                data = pd.concat([data, reviews], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                return data\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = main()\n",
    "    data = data.dropna()\n",
    "    print(data)\n",
    "\n",
    "data.to_csv('2021_Drugs_Com_Reviews.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d06ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9646073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
